{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import csv\n",
    "import signal\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "from concurrent.futures import ProcessPoolExecutor, TimeoutError\n",
    "\n",
    "from chocoq.problems.facility_location_problem import generate_flp\n",
    "from chocoq.problems.graph_coloring_problem import generate_gcp\n",
    "from chocoq.problems.k_partition_problem import generate_kpp\n",
    "from chocoq.problems.job_scheduling_problem import generate_jsp\n",
    "from chocoq.problems.traveling_salesman_problem import generate_tsp\n",
    "from chocoq.problems.set_cover_problem import generate_scp\n",
    "from chocoq.solvers.optimizers import CobylaOptimizer, AdamOptimizer\n",
    "from chocoq.solvers.qiskit import (\n",
    "    PenaltySolver, CyclicSolver, HeaSolver, ChocoSolver, \n",
    "    AerGpuProvider, AerProvider, FakeBrisbaneProvider, FakeKyivProvider, FakeTorinoProvider, DdsimProvider,\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)  # display all rows\n",
    "pd.set_option('display.max_columns', None)  # display all columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cases = 10  # The number of cases in each benchmark\n",
    "problem_scale = 4 # The problem scale, 1 is the minimal scale like F1,K1,G1 in Table 1 of paper\n",
    "#2 means F2 K2 ... In CPU version, this benchmarks with higher scale is much slower when solving with baselines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate the problem to be solved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "flp_problems_pkg, flp_configs_pkg = generate_flp(num_cases, [(1, 2), (2, 3), (3, 3), (3, 4)][:problem_scale], 1, 20)\n",
    "gcp_problems_pkg, gcp_configs_pkg = generate_gcp(num_cases, [(3, 1), (3, 2), (4, 1), (4, 2)][:problem_scale])\n",
    "kpp_problems_pkg, kpp_configs_pkg = generate_kpp(num_cases, [(4, 2, 3), (5, 3, 4), (6, 3, 5), (7, 3, 6)][:problem_scale], 1, 20)\n",
    "jsp_problems_pkg, jsp_configs_pkg = generate_jsp(num_cases, [(2, 2, 3), (2, 3, 4), (3, 3, 5), (3, 4, 6)][:problem_scale], 1, 20)\n",
    "scp_problems_pkg, scp_configs_pkg = generate_scp(num_cases, [(4, 4), (5, 5), (6, 6), (7, 7)][:problem_scale])\n",
    "\n",
    "configs_pkg = flp_configs_pkg + gcp_configs_pkg + kpp_configs_pkg + jsp_configs_pkg + scp_configs_pkg\n",
    "with open(f\"2_table_all_scale.config\", \"w\") as file:\n",
    "    for pkid, configs in enumerate(configs_pkg):\n",
    "        for problem in configs:\n",
    "            file.write(f'{pkid}: {problem}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on circuit depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_path = '2_table_depth_all_scale'\n",
    "\n",
    "problems_pkg = flp_problems_pkg + gcp_problems_pkg + kpp_problems_pkg + jsp_problems_pkg + scp_problems_pkg\n",
    "\n",
    "metrics_lst = ['culled_depth', 'num_params']\n",
    "solvers = [PenaltySolver, CyclicSolver, HeaSolver, ChocoSolver]\n",
    "headers = [\"pkid\", 'method', 'layers'] + metrics_lst\n",
    "\n",
    "def process_layer(prb, num_layers, solver, metrics_lst):\n",
    "    opt = CobylaOptimizer(max_iter=200)\n",
    "    ddsim = DdsimProvider()\n",
    "    cpu = AerProvider()\n",
    "    gpu = AerGpuProvider()\n",
    "    used_solver = solver(\n",
    "        prb_model = prb,\n",
    "        optimizer = opt,\n",
    "        # Select CPU or GPU simulator\n",
    "        # cpu simulator, comment it when use GPU\n",
    "        # provider = cpu if solver in [PenaltySolver, CyclicSolver, HeaSolver] else ddsim,\n",
    "        # uncomment the line below to use GPU simulator\n",
    "        provider = gpu if solver in [PenaltySolver, CyclicSolver, HeaSolver] else ddsim,\n",
    "        num_layers = num_layers,\n",
    "        shots = 1024,\n",
    "    )\n",
    "    metrics = used_solver.circuit_analyze(metrics_lst)\n",
    "    return metrics\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    set_timeout = 60 * 60 * 24 # Set timeout duration\n",
    "    num_complete = 0\n",
    "    with open(f'{new_path}.csv', mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(headers)  # Write headers once\n",
    "\n",
    "    num_processes_cpu = os.cpu_count() // 2\n",
    "    with ProcessPoolExecutor(max_workers=num_processes_cpu) as executor:\n",
    "        futures = []\n",
    "        for solver in solvers:\n",
    "            for pkid, problems in enumerate(problems_pkg):\n",
    "                for problem in problems:\n",
    "                    if solver == ChocoSolver:\n",
    "                        num_layers = 1\n",
    "                    else:\n",
    "                        num_layers = 5\n",
    "                    future = executor.submit(process_layer, problem, num_layers, solver, metrics_lst)\n",
    "                    futures.append((future, pkid, solver.__name__, num_layers))\n",
    "\n",
    "        start_time = time.perf_counter()\n",
    "        for future, pkid, solver, num_layers in futures:\n",
    "            current_time = time.perf_counter()\n",
    "            remaining_time = max(set_timeout - (current_time - start_time), 0)\n",
    "            diff = []\n",
    "            try:\n",
    "                result = future.result(timeout=remaining_time)\n",
    "                diff.extend(result)\n",
    "                print(f\"Task for problem {pkid}, num_layers {num_layers} executed successfully.\")\n",
    "            except MemoryError:\n",
    "                diff.append('memory_error')\n",
    "                print(f\"Task for problem {pkid}, num_layers {num_layers} encountered a MemoryError.\")\n",
    "            except TimeoutError:\n",
    "                diff.append('timeout')\n",
    "                print(f\"Task for problem {pkid}, num_layers {num_layers} timed out.\")\n",
    "            finally:\n",
    "                row = [pkid, solver, num_layers] + diff\n",
    "                with open(f'{new_path}.csv', mode='a', newline='') as file:\n",
    "                    writer = csv.writer(file)\n",
    "                    writer.writerow(row)  # Write row immediately\n",
    "                num_complete += 1\n",
    "                if num_complete == len(futures):\n",
    "                    print(f'Data has been written to {new_path}.csv')\n",
    "                    for process in executor._processes.values():\n",
    "                        os.kill(process.pid, signal.SIGTERM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '2_table_depth_all_scale.csv'\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "grouped_df = df.groupby(['pkid', 'layers', 'method'], as_index=False).agg({\n",
    "    \"culled_depth\": 'mean',\n",
    "})\n",
    "\n",
    "values = [\"culled_depth\"]\n",
    "pivot_df = grouped_df.pivot(index =['pkid'], columns='method', values=values)\n",
    "\n",
    "method_order = ['PenaltySolver', 'CyclicSolver', 'HeaSolver', 'ChocoSolver']\n",
    "pivot_df = pivot_df.reindex(columns=pd.MultiIndex.from_product([values, method_order]))\n",
    "\n",
    "pivot_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on other metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_path = '2_table_evaluate_all_scale'\n",
    "\n",
    "problems_pkg = list(\n",
    "    itertools.chain(\n",
    "        enumerate(flp_problems_pkg),\n",
    "        enumerate(gcp_problems_pkg),\n",
    "        enumerate(kpp_problems_pkg),\n",
    "        enumerate(jsp_problems_pkg),\n",
    "        enumerate(scp_problems_pkg),\n",
    "    )\n",
    ")\n",
    "\n",
    "solvers = [PenaltySolver, CyclicSolver, HeaSolver, ChocoSolver]\n",
    "evaluation_metrics = ['best_solution_probs', 'in_constraints_probs', 'ARG', 'iteration_count', 'classcial', 'quantum', 'run_times']\n",
    "headers = ['pkid', 'pbid', 'layers', \"variables\", 'constraints', 'method'] + evaluation_metrics\n",
    "\n",
    "def process_layer(prb, num_layers, solver):\n",
    "    opt = CobylaOptimizer(max_iter=200)\n",
    "    ddsim = DdsimProvider()\n",
    "    cpu = AerProvider()\n",
    "    gpu = AerGpuProvider()\n",
    "    prb.set_penalty_lambda(400)\n",
    "    used_solver = solver(\n",
    "        prb_model = prb,\n",
    "        optimizer = opt,\n",
    "        # 根据配置的环境选择CPU或GPU\n",
    "        # provider = cpu if solver in [PenaltySolver, CyclicSolver, HeaSolver] else ddsim,\n",
    "        provider = gpu if solver in [PenaltySolver, CyclicSolver, HeaSolver] else ddsim,\n",
    "        num_layers = num_layers,\n",
    "        shots = 1024,\n",
    "    )\n",
    "    used_solver.solve()\n",
    "    eval = used_solver.evaluation()\n",
    "    time = list(used_solver.time_analyze())\n",
    "    run_times = used_solver.run_counts()\n",
    "    return eval + time + [run_times]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    all_start_time = time.perf_counter()\n",
    "    set_timeout = 60 * 60 * 2 # Set timeout duration\n",
    "    num_complete = 0\n",
    "\n",
    "    with open(f'{new_path}.csv', mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(headers)  # 写入标题\n",
    "\n",
    "    num_processes_cpu = os.cpu_count()\n",
    "    # pkid-pbid: 问题包序-包内序号\n",
    "    for pkid, (diff_level, problems) in enumerate(problems_pkg):\n",
    "        for solver in solvers:\n",
    "            if solver in [PenaltySolver, CyclicSolver, HeaSolver]:\n",
    "                num_processes = 2**(4 - diff_level) + 1\n",
    "            else:\n",
    "                num_processes = 100\n",
    "\n",
    "            with ProcessPoolExecutor(max_workers=num_processes) as executor:\n",
    "                futures = []\n",
    "                if solver == ChocoSolver:\n",
    "                    layer = 1\n",
    "                else:\n",
    "                    layer = 5\n",
    "\n",
    "                for pbid, prb in enumerate(problems):\n",
    "                    print(f'{pkid}-{pbid}, {layer}, {solver} build')\n",
    "                    future = executor.submit(process_layer, prb, layer, solver)\n",
    "                    futures.append((future, prb, pkid, pbid, layer, solver.__name__))\n",
    "\n",
    "                start_time = time.perf_counter()\n",
    "                for future, prb, pkid, pbid, layer, solver in futures:\n",
    "                    current_time = time.perf_counter()\n",
    "                    remaining_time = max(set_timeout - (current_time - start_time), 0)\n",
    "                    diff = []\n",
    "                    try:\n",
    "                        metrics = future.result(timeout=remaining_time)\n",
    "                        diff.extend(metrics)\n",
    "                        print(f\"Task for problem {pkid}-{pbid} L={layer} {solver} executed successfully.\")\n",
    "                    except MemoryError:\n",
    "                        print(f\"Task for problem {pkid}-{pbid} L={layer} {solver} encountered a MemoryError.\")\n",
    "                        for dict_term in evaluation_metrics:\n",
    "                            diff.append('memory_error')\n",
    "                    except TimeoutError:\n",
    "                        print(f\"Task for problem {pkid}-{pbid} L={layer} {solver} timed out.\")\n",
    "                        for dict_term in evaluation_metrics:\n",
    "                            diff.append('timeout')\n",
    "                    except Exception as e:\n",
    "                        print(f\"An error occurred: {e}\")\n",
    "                    finally:\n",
    "                        row = [pkid, pbid, layer, len(prb.variables), len(prb.lin_constr_mtx), solver] + diff\n",
    "                        with open(f'{new_path}.csv', mode='a', newline='') as file:\n",
    "                            writer = csv.writer(file)\n",
    "                            writer.writerow(row)  # Write row immediately\n",
    "                        num_complete += 1\n",
    "                        if num_complete == len(futures):\n",
    "                            print(f'problem_pkg_{pkid} has finished')\n",
    "                            for process in executor._processes.values():\n",
    "                                os.kill(process.pid, signal.SIGTERM)\n",
    "    print(f'Data has been written to {new_path}.csv')\n",
    "    print(time.perf_counter()- all_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('2_table_evaluate_all_scale.csv')\n",
    "\n",
    "df = df.drop(columns=['pbid'])\n",
    "df = df[df['ARG'] <= 100000]\n",
    "\n",
    "grouped_df = df.groupby(['pkid', 'layers', 'variables', 'constraints', 'method'], as_index=False).agg({\n",
    "    \"ARG\": 'mean',\n",
    "    'in_constraints_probs': 'mean',\n",
    "    'best_solution_probs': 'mean',\n",
    "    'iteration_count':'mean',\n",
    "    'classcial':'mean',\n",
    "    'run_times':'mean',\n",
    "})\n",
    "\n",
    "## 分组并把组作为索引\n",
    "pivot_df = grouped_df.pivot(index =['pkid', 'variables', 'constraints'], columns='method', values=[\"best_solution_probs\",'in_constraints_probs', 'ARG'])\n",
    "method_order = ['PenaltySolver', 'CyclicSolver', 'HeaSolver', 'ChocoSolver']\n",
    "pivot_df = pivot_df.reindex(columns=pd.MultiIndex.from_product([[\"best_solution_probs\",'in_constraints_probs', 'ARG'], method_order]))\n",
    "\n",
    "pivot_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The method we use to calculate the improvement is as follows: for each benchmark, we compute the improvement ratio. Then, we take the arithmetic mean of the improvement ratios across all benchmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row-wise ratio calculation\n",
    "# methods = ['PenaltySolver', 'CyclicSolver', 'HeaSolver']\n",
    "methods = ['CyclicSolver']\n",
    "ratios_rowwise = []\n",
    "\n",
    "for idx, row in pivot_df.iterrows():\n",
    "    choco_best_solution_probs = row['best_solution_probs', 'ChocoSolver']\n",
    "    choco_in_constraints_probs = row['in_constraints_probs', 'ChocoSolver']\n",
    "    choco_ARG = row['ARG', 'ChocoSolver']\n",
    "\n",
    "    for method in methods:\n",
    "        ratio_best_solution_probs = choco_best_solution_probs / row['best_solution_probs', method]\n",
    "        ratio_in_constraints_probs = choco_in_constraints_probs / row['in_constraints_probs', method]\n",
    "        ratio_ARG = row['ARG', method] / choco_ARG\n",
    "        \n",
    "        ratios_rowwise.append({\n",
    "            'pkid': row.name[0], \n",
    "            'variables': row.name[1], \n",
    "            'constraints': row.name[2],\n",
    "            'method': method,\n",
    "            'ratio_best_solution_probs': ratio_best_solution_probs,\n",
    "            'ratio_in_constraints_probs': ratio_in_constraints_probs,\n",
    "            'ratio_ARG': ratio_ARG\n",
    "        })\n",
    "\n",
    "# Convert the result into a DataFrame\n",
    "ratios_rowwise_df = pd.DataFrame(ratios_rowwise)\n",
    "\n",
    "# Calculate the average ratio for each metric\n",
    "ratios_avg_df = ratios_rowwise_df.groupby('method').mean()[['ratio_best_solution_probs', 'ratio_in_constraints_probs', 'ratio_ARG']]\n",
    "ratios_avg_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "choco_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
